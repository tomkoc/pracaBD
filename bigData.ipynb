{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalnie kluczowa zmiana od miejsca, gdzie jest napisane !!!!Przełom\n",
    "po drodze jakieś eksperymenty z ustalaniem typow\n",
    "Nowa funkcja cleaningRDD3 zmieniająca na DF i jakos sie nie wykrzacza - nie wiem, czy jest wydajna, ale cos robi\n",
    "\n",
    "Kolejny etap to co sie da pozamieniac na inty, połaczyć pare tabelek i ułożyć do wszystkiego historię"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"BDProject\").setMaster(\"local[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=BDProject, master=local[3]) created by __init__ at <ipython-input-4-38871edff11b>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-38871edff11b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\apache-spark\\spark-2.2.0-bin-hadoop2\\spark-2.2.0-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mC:\\apache-spark\\spark-2.2.0-bin-hadoop2\\spark-2.2.0-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    297\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 299\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=BDProject, master=local[3]) created by __init__ at <ipython-input-4-38871edff11b>:1 "
     ]
    }
   ],
   "source": [
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawBadges=sc.textFile(\"travel.stackexchange.com\\Badges.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawUsers=sc.textFile(\"travel.stackexchange.com\\\\Users.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"utf-8\"?>',\n",
       " '<users>',\n",
       " '  <row Id=\"-1\" Reputation=\"1\" CreationDate=\"2011-06-21T15:16:44.000\" DisplayName=\"Community\" LastAccessDate=\"2011-06-21T15:16:52.063\" Location=\"on the server farm\" AboutMe=\"&lt;p&gt;Hi, I\\'m not really a person.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I\\'m a background process that helps keep this site clean!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do things like&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Randomly poke old unanswered questions every hour so they get some attention&lt;/li&gt;&#xA;&lt;li&gt;Own community questions and answers so nobody gets unnecessary reputation from them&lt;/li&gt;&#xA;&lt;li&gt;Own downvotes on spam/evil posts that get permanently deleted&lt;/li&gt;&#xA;&lt;li&gt;Own suggested edits from anonymous users&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://meta.stackexchange.com/a/92006&quot;&gt;Remove abandoned questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;\" Views=\"30\" UpVotes=\"21\" DownVotes=\"17\" Age=\"7\" AccountId=\"-1\" />']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawUsers.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaningRDD(RDDIn):\n",
    "    def cleaning(listIn):\n",
    "        listOut=[]\n",
    "        for x in listIn:\n",
    "            if listIn.index(x)%2==0:\n",
    "                listOut.append(x.replace(' ','').replace('<','').replace('=',''))\n",
    "            else:\n",
    "                listOut.append(x)\n",
    "        return {listOut[i]:listOut[i+1] for i in range(0,len(listOut)-1,2)}\n",
    "    return RDDIn.filter(lambda x: x.startswith('  <row Id=')).\\\n",
    "map(lambda x: x.split('\"')).map(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badges=cleaningRDD(rawBadges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Class': '3',\n",
       "  'Date': '2011-06-21T20:16:50.113',\n",
       "  'Name': 'Autobiographer',\n",
       "  'TagBased': 'False',\n",
       "  'UserId': '2',\n",
       "  'rowId': '1'},\n",
       " {'Class': '3',\n",
       "  'Date': '2011-06-21T20:16:50.113',\n",
       "  'Name': 'Autobiographer',\n",
       "  'TagBased': 'False',\n",
       "  'UserId': '4',\n",
       "  'rowId': '2'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badges.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number_tryexcept(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slownik={'Class': '-3','anyDate': '2011-06-21T20:16:48.910','Name': 'Autobiographer','TagBased': 'False','UserId': '2-','rowId': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slownik2={'Class': '-3','anyDate': '2011-06-21T20:16:48.910','UserId': '2-','rowId': '1','Name': 'Autobiographer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in slownik.keys():\n",
    "    if is_number_tryexcept(slownik[x])==True:\n",
    "        slownik[x]=int(slownik[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Class', 'anyDate', 'Name', 'TagBased', 'UserId', 'rowId'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slownik.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitowanie(slownik):\n",
    "    from datetime import datetime\n",
    "    for x in slownik.keys():\n",
    "        if slownik[x].replace('-','').isdigit():\n",
    "            slownik[x]=int(slownik[x])\n",
    "        elif x.find('Date')>0:\n",
    "            slownik[x]=datetime.strptime(slownik[x][0:-4],'%Y-%m-%dT%H:%M:%S')\n",
    "    return slownik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowSchema=Row(**slownik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Class='-3', Name='Autobiographer', TagBased='False', UserId='2-', anyDate='2011-06-21T20:16:48.910', rowId='1')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(-3={'Class': '-3', 'anyDate': '2011-06-21T20:16:48.910', 'Name': 'Autobiographer', 'TagBased': 'False', 'UserId': '2-', 'rowId': '1'})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowSchema(slownik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=rowSchema(*slownik.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Class='-3', anyDate='2011-06-21T20:16:48.910', Name='Autobiographer', TagBased='False', UserId='2-', rowId='1')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 2, 1, 0, 0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x='2017-01-02dsdsds'\n",
    "y=datetime.strptime(x,'%Y-%d-%mdsdsds')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3, datetime.datetime(2011, 6, 21, 20, 16, 48), 'Autobiographer', 'False', 2, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slownik.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Class': 3,\n",
       " 'Name': 'Autobiographer',\n",
       " 'TagBased': 'False',\n",
       " 'UserId': 2,\n",
       " 'anyDate': datetime.datetime(2011, 6, 21, 20, 16, 48),\n",
       " 'rowId': 1}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitowanie(slownik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 6, 21, 20, 16, 48)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slownik['anyDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame_1') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badgesInt=badges.map(lambda x: digitowanie(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(badgesInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badgesDF=badgesInt.map(lambda x: Row(**x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Class: long (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- TagBased: string (nullable = true)\n",
      " |-- UserId: long (nullable = true)\n",
      " |-- rowId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "badgesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Class': 3,\n",
       "  'Date': datetime.datetime(2011, 6, 21, 20, 16, 50),\n",
       "  'Name': 'Autobiographer',\n",
       "  'TagBased': 'False',\n",
       "  'UserId': 2,\n",
       "  'rowId': 1},\n",
       " {'Class': 3,\n",
       "  'Date': datetime.datetime(2011, 6, 21, 20, 16, 50),\n",
       "  'Name': 'Autobiographer',\n",
       "  'TagBased': 'False',\n",
       "  'UserId': 4,\n",
       "  'rowId': 2}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badges2=cleaningRDD2(rawBadges)\n",
    "badges2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaningRDD2(RDDIn):\n",
    "    def cleaning(listIn):\n",
    "        listOut=[]\n",
    "        for x in listIn:\n",
    "            if listIn.index(x)%2==0:\n",
    "                listOut.append(x.replace(' ','').replace('<','').replace('=',''))\n",
    "            else:\n",
    "                listOut.append(x)\n",
    "        return {listOut[i]:listOut[i+1] for i in range(0,len(listOut)-1,2)}\n",
    "    def isItNumber(s):\n",
    "        \"\"\" Returns True if string is a number. \"\"\"\n",
    "        try:\n",
    "            int(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    def digitowanie(slownik):\n",
    "        from datetime import datetime\n",
    "        for x in slownik.keys():\n",
    "            if isItNumber(slownik[x])==True:\n",
    "                slownik[x]=int(slownik[x])\n",
    "            elif x.find('Date')>0:\n",
    "                slownik[x]=datetime.strptime(slownik[x][0:-4],'%Y-%m-%dT%H:%M:%S')\n",
    "        return slownik\n",
    "    return RDDIn.filter(lambda x: x.startswith('  <row Id=')).\\\n",
    "map(lambda x: x.split('\"')).map(cleaning).map(digitowanie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField,\\\n",
    "TimestampType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Class: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- TagBased: string (nullable = true)\n",
      " |-- UserId: integer (nullable = true)\n",
      " |-- rowId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "users2=cleaningRDD2(rawUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users2DF=users2.map(lambda x: Row(**x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AboutMe: string (nullable = true)\n",
      " |-- AccountId: long (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- DisplayName: string (nullable = true)\n",
      " |-- DownVotes: long (nullable = true)\n",
      " |-- LastAccessDate: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Reputation: long (nullable = true)\n",
      " |-- UpVotes: long (nullable = true)\n",
      " |-- Views: long (nullable = true)\n",
      " |-- rowId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users2DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users3=users2.flatMap(lambda x: list(x.keys())).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!Przełom:-)\n",
    "\n",
    "Tutaj mamy nową wersje funkcji - z danego RDD robi Data Frame ze stringami na razie, ale radzi sobie ze słownikami z niekompletnymi polami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaningRDD3(RDDIn):\n",
    "    def preCleanUp(RDDIn):\n",
    "        def cleaning(listIn):\n",
    "            listOut=[]\n",
    "            for x in listIn:\n",
    "                if listIn.index(x)%2==0:\n",
    "                    listOut.append(x.replace(' ','').replace('<','').replace('=',''))\n",
    "                else:\n",
    "                    listOut.append(x)\n",
    "            return {listOut[i]:listOut[i+1] for i in range(0,len(listOut)-1,2)}\n",
    "        return RDDIn.filter(lambda x: x.startswith('  <row Id=')).map(lambda x: x.split('\"')).map(cleaning)\n",
    "    dictRDD=preCleanUp(RDDIn)\n",
    "    listOfColums=dictRDD.flatMap(lambda x: list(x.keys())).distinct().collect()\n",
    "    def newDict(dictIn):\n",
    "        for col in listOfColums:\n",
    "            if col not in dictIn.keys():\n",
    "                dictIn[col]=None\n",
    "        return dictIn\n",
    "    #nie mam bladego pojęcia dlaczego dziadostwo nie działa bez sampleRatio\n",
    "    return dictRDD.map(newDict).map(lambda x: Row(**x)).toDF(sampleRatio=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ma byc funkcja ktora dodaje brakujace pola do slownika, zeby pozniej rowy mialy tyle samo wartosci\n",
    "def newDictTest(dictIn,listOfColums):\n",
    "    for col in listOfColums:\n",
    "        if col not in dictIn.keys():\n",
    "            dictIn[col]=None\n",
    "    return dictIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDict={'a':1,'b':2,'d':22}\n",
    "testCol=['a','ba','s','w','da']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'ba': None, 'd': 22, 'da': None, 's': None, 'w': None}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDictTest(testDict,testCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "users4=cleaningRDD3(rawUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AboutMe: string (nullable = true)\n",
      " |-- AccountId: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- CreationDate: string (nullable = true)\n",
      " |-- DisplayName: string (nullable = true)\n",
      " |-- DownVotes: string (nullable = true)\n",
      " |-- LastAccessDate: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- ProfileImageUrl: string (nullable = true)\n",
      " |-- Reputation: string (nullable = true)\n",
      " |-- UpVotes: string (nullable = true)\n",
      " |-- Views: string (nullable = true)\n",
      " |-- WebsiteUrl: string (nullable = true)\n",
      " |-- rowId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---+--------------------+-----------+---------+--------------------+------------------+---------------+----------+-------+-----+----------+-----+\n",
      "|             AboutMe|AccountId|Age|        CreationDate|DisplayName|DownVotes|      LastAccessDate|          Location|ProfileImageUrl|Reputation|UpVotes|Views|WebsiteUrl|rowId|\n",
      "+--------------------+---------+---+--------------------+-----------+---------+--------------------+------------------+---------------+----------+-------+-----+----------+-----+\n",
      "|&lt;p&gt;Hi, I'm ...|       -1|  7|2011-06-21T15:16:...|  Community|       17|2011-06-21T15:16:...|on the server farm|           null|         1|     21|   30|      null|   -1|\n",
      "+--------------------+---------+---+--------------------+-----------+---------+--------------------+------------------+---------------+----------+-------+-----+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users4.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AboutMe',\n",
       " 'AccountId',\n",
       " 'Age',\n",
       " 'CreationDate',\n",
       " 'DisplayName',\n",
       " 'DownVotes',\n",
       " 'LastAccessDate',\n",
       " 'Location',\n",
       " 'ProfileImageUrl',\n",
       " 'Reputation',\n",
       " 'UpVotes',\n",
       " 'Views',\n",
       " 'WebsiteUrl',\n",
       " 'rowId']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----+\n",
      "|        DisplayName|Reputation| Age|\n",
      "+-------------------+----------+----+\n",
      "|     Kevin Montrose|       101|null|\n",
      "|          user27478|      4550|null|\n",
      "|          mrigasira|       904|null|\n",
      "|             jeroen|       306|null|\n",
      "|          Gagravarr|     45427|null|\n",
      "|          HedgeMage|       370|null|\n",
      "|            Rodolfo|      1202|null|\n",
      "|    theycallmemorty|       441|null|\n",
      "|                Ben|       178|null|\n",
      "|       Joel Spolsky|      7203|null|\n",
      "|Francesca Venturini|       140|null|\n",
      "|                Eri|       310|null|\n",
      "|            Workman|       101|null|\n",
      "|            Vitalik|       184|null|\n",
      "|              fmark|       101|null|\n",
      "|               z  -|       260|null|\n",
      "|                nic|      5045|null|\n",
      "|             Beaker|      3608|null|\n",
      "|   TheEnigmaMachine|       658|null|\n",
      "|            Sufendy|      2439|null|\n",
      "+-------------------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users4.select('DisplayName','Reputation', 'Age').where(users4.Age.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+----------+\n",
      "|     DisplayName| Age|Reputation|\n",
      "+----------------+----+----------+\n",
      "|       Community|   7|         1|\n",
      "|    Geoff Dalgas|  41|       101|\n",
      "|     Nick Craver|  33|       101|\n",
      "|          Emmett|  32|       101|\n",
      "|  Kevin Montrose|null|       101|\n",
      "|   Jimmy Sawczuk|  31|       101|\n",
      "|        Seanland|  33|      1206|\n",
      "|    silent1mezzo|  31|      1978|\n",
      "|     Darren Kopp|  33|      1182|\n",
      "|       user27478|null|      4550|\n",
      "|      daybreaker|  37|       466|\n",
      "|    Matthew Read|  31|      1763|\n",
      "|         cerealk|  40|       101|\n",
      "|       mrigasira|null|       904|\n",
      "|           VMAtm|  34|     19165|\n",
      "|Rebecca Chernoff|  34|       101|\n",
      "|          jeroen|null|       306|\n",
      "|   Michael Pryor|  42|      1684|\n",
      "|       Gagravarr|null|     45427|\n",
      "|          Nicole|  36|       707|\n",
      "+----------------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users4.select('DisplayName','Age','Reputation').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test na Tagach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawTags=sc.textFile(\"travel.stackexchange.com\\Tags.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagsDF=cleaningRDD3(rawTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Count: string (nullable = true)\n",
      " |-- ExcerptPostId: string (nullable = true)\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- WikiPostId: string (nullable = true)\n",
      " |-- rowId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+\n",
      "|Count|  TagName|WikiPostId|\n",
      "+-----+---------+----------+\n",
      "|   92|argentina|      2393|\n",
      "+-----+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.select('Count','TagName','WikiPostId').where(tagsDF.TagName=='argentina').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test na Comments - początkowo się nie udał :-( ale po ustaleniu sampleRatio=100 znowu sie udalo, tylko nie wiadomo dlaczego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawComments=sc.textFile(\"travel.stackexchange.com\\Comments.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"utf-8\"?>',\n",
       " '<comments>',\n",
       " '  <row Id=\"1\" PostId=\"8\" Score=\"1\" Text=\"Indeed, recommendations in general are off-topic.  [This page](http://travel.stackexchange.com/questions/how-to-ask-beta) lists a couple blog posts that explain exactly why these questions aren\\'t a good fit for the network.\" CreationDate=\"2011-06-21T23:26:02.317\" UserId=\"20\" />']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawComments.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=cleaningRDD3(rawComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawComments.toDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CreationDate: string (nullable = true)\n",
      " |-- PostId: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- UserDisplayName: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- rowId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
